<html> <head> <title>Singularitarianism</title></head><body>{{Transhumanism}}
'''Singularitarianism''' is a [[technocentrism|technocentric]] [[ideology]] and [[social movement]] that is defined by the belief that a [[technological singularity]] — the creation of a [[superintelligence]] — is a likely possibility within the medium-term future, and that deliberate action ought to be taken to ensure that “the Singularity” occurs in a way beneficial to [[human]]s. While some [[futurist]]s speculate on the possibility and nature of a technological singularity, Singularitarians believe it is not only possible, but desirable if guided safely. Accordingly, they might sometimes dedicate their lives to acting in ways they believe will contribute to its rapid yet safe implementation.<ref name="Kurzweil 2005">{{cite book| last = Kurzweil | first = Raymond | title = [[The Singularity Is Near|The Singularity Is Near: When Humans Transcend Biology]] | publisher = Viking Adult| year = 2005 | isbn = 0-670-03384-7| oclc = 224517172}}</ref> 

The term "Singularitarian" was originally defined by [[Extropianism|Extropian]] thinker Mark Plus (Mark Potts) in 1991 to mean "one who believes the concept of a Singularity". This term has since been redefined to mean "Singularity activist" or "friend of the Singularity"; that is, one who acts so as to bring about the Singularity.<ref>http://www.extropy.org/neologo.htm#s Neologisms of Extropy</ref> Inventor and futurist [[Ray Kurzweil]], author of the 2005 book ''[[The Singularity Is Near|The Singularity Is Near: When Humans Transcend Biology ]]'', defines a Singularitarian as someone "who understands the Singularity and who has reflected on its implications for his or her own life", and predicts [[The Singularity Is Near#2045: The Singularity|the Singularity will occur in 2045]].<ref name="Kurzweil 2005"/>

Often ridiculing the Singularity as "the [[Rapture]] of the [[Nerd]]s", some critics have dismissed Singularitarianism as [[technological utopianism]] turned into a [[new religious movement]].<ref name="Horgan 2008">{{cite paper | last = Horgan | first = John | authorlink = John Horgan (American journalist) | title = The Consciousness Conundrum | year = 2008 | url = http://spectrum.ieee.org/biomedical/imaging/the-consciousness-conundrum/0 | accessdate = 2008-12-17}}</ref> Some, however, warn that the interest in the Singularity by corporate and military interests provides a clue as to the direction and social implication of [[transhumanism|transhumanist]] technology.<ref name="Correia 2010">{{cite paper | last = Correia | first = David | authorlink = | title = The Singularity Movement: If Only Glenn Beck Were a Cyborg | year = 2010 | url = http://www.counterpunch.org/correia09152010.html | accessdate = 2010-12-15}}</ref> Alarmed by Singularitarian ambitions, their strongest opponents have called for violent [[direct action]] to "stop the Singularity".<ref name="Green Anarchy 2005">{{cite paper| author = mosh@terran hacker corps |title = A Singular Rapture | year = 2005 | url = http://web.archive.org/web/20071110060923/http://www.greenanarchy.org/index.php?action=viewwritingdetail&writingId=182 | accessdate=2008-12-11}}</ref>

==History== 

In 1993, American [[mathematician]], [[computer scientist]], and [[science fiction]] author [[Vernor Vinge]] speculated that the moment might come when some computers are smarter than humans and  may have coined the term "the Singularity" to describe this moment.<ref name="nytimes july09"/> He suggested that the Singularity may be somewhat or possibly very dangerous for humans.<ref>[http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html The Coming Technological Singularity: How to Survive in the Post-Human Era], by Vernor Vinge, Department of Mathematical Sciences, San Diego State University, (c) 1993 by Vernor Vinge.</ref>

A growing minority of computer scientists and [[technical journalism|technical journalist]]s subsequently adopted a belief in the Singularity and began using the term in their writings: 

{{quotation|It feels like something big is about to happen: graphs show us the yearly growth of populations, atmospheric concentrations of carbon dioxide, Net addresses, and Mbytes per dollar. They all soar up to form an asymptote just beyond the turn of the century: The Singularity. The end of everything we know. The beginning of something we may never understand.|[[W. Daniel Hillis|Danny Hillis]]|"The Millennium Clock", [[Wired (magazine)|''Wired'' magazine]], 1995}}

Singularitarianism coalesced into a coherent ideology in 2000 when American [[artificial intelligence]] researcher [[Eliezer Yudkowsky]] wrote the first version of ''The Singularitarian Principles'', in which he stated that there are four qualities that define a “Singularitarian”:<ref>[http://yudkowsky.net/sing/principles.html Singularitarian Principles]"</ref> 
*A Singularitarian believes that the Singularity is possible and desirable.
*A Singularitarian actually ''works'' to bring about the Singularity.
*A Singularitarian views the Singularity as an entirely secular, non-mystical process &mdash; not the culmination of any form of religious prophecy or destiny.
*A Singularitarian believes the Singularity should benefit the entire world, and should not be a means to benefit any specific individual or group.

In the same document, Yudkowsky described the [[technological utopianism]] at the heart of Singularitarianism as promising “[[apotheosis]]”: 

{{quotation|The Singularity holds out the possibility of winning the Grand Prize, the true Utopia, the best-of-all-possible-worlds - not just freedom from pain and stress or a sterile round of endless physical pleasures, but the prospect of endless growth for every human being - growth in mind, in intelligence, in strength of personality; life without bound, without end; experiencing everything we've dreamed of experiencing, becoming everything we've ever dreamed of being; not for a billion years, or ten-to-the-billionth years, but forever... or perhaps embarking together on some still greater adventure of which we cannot even conceive."<ref>http://yudkowsky.net/obsolete/principles.html The Singularitarian Principles by Eliezer Yudkowsky last updated 05/14/2001; page retrieved 9th November 2010</ref>}}

In June 2000 Yudkowsky, with the support of [[Internet entrepreneur]]s Brian Atkins and Sabine Atkins, founded the [[Singularity Institute for Artificial Intelligence]] to work towards the creation of self-improving [[Friendly artificial intelligence|Friendly AI]]. The Singularity Institute's writings argue for the idea that an AI with the ability to improve upon its own design ([[Seed AI]]) would rapidly lead to [[superintelligence]]. These Singularitarians believe that reaching the Singularity swiftly and safely is the best possible way to minimize net [[existential risk]].

Many people believe a technological singularity is possible without adopting Singularitarianism as a moral philosophy. Although the exact numbers are hard to quantify, Singularitarianism is presently a small movement, which includes British [[transhumanism|transhumanist]] philosopher [[Nick Bostrom]]. American inventor and futurist [[Ray Kurzweil]], who predicts [[The Singularity Is Near#2045: The Singularity|the Singularity will occur in 2045]], greatly contributed to popularizing Singularitarianism with his 2005 book ''[[The Singularity Is Near|The Singularity Is Near: When Humans Transcend Biology ]]''.<ref name="Kurzweil 2005"/> 

{{quotation|What, then, is the Singularity? It's a future period during which the pace of technological change will be so rapid, its impact so deep, that human life will be irreversibly transformed. Although neither utopian or dystopian, this epoch will transform the concepts we rely on to give meaning to our lives, from our business models to the cycle of human life, including death itself. Understanding the Singularity will alter our perspective on the significance of our past and the ramifications for our future. To truly understand it inherently changes one's view of life in general and one's particular life. I regard someone who understands the Singularity and who has reflected on its implications for his or her own life as a “singularitarian.”<ref name="Kurzweil 2005"/>}}

With the support of [[NASA]], [[Google]] and a broad range of [[technology forecasting|technology forecasters]] and [[technocapitalism|technocapitalists]], the [[Singularity University]] opened in June 2009 at the [[NASA Research Park]] in [[Silicon Valley]] with the goal of preparing the next generation of leaders to address the challenges of [[accelerating change]].

In July 2009, academics and technical experts, some of whom were Singularitarians, participated in a conference organized by the [[Association for the Advancement of Artificial Intelligence]] (AAAI) to discuss the potential impact of [[robot]]s and computers and the impact of the hypothetical possibility that they could become self-sufficient and able to make their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy, and to what degree they could use such abilities to possibly pose any threat or hazard (i.e. [[cybernetic revolt]]). They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They warned that some [[computer viruses]] can evade elimination and have achieved "cockroach intelligence." They asserted that self-awareness as depicted in [[science fiction]] is probably unlikely, but that there were other potential hazards and pitfalls.<ref name="nytimes july09"> [http://www.nytimes.com/2009/07/26/science/26robot.html?_r=1&ref=todayspaper Scientists Worry Machines May Outsmart Man] By JOHN MARKOFF, NY Times, July 26, 2009. </ref> Some experts and academics have questioned the use of [[military robot|robots for military combat]], especially when such robots are given some degree of autonomous functions.<ref> [http://news.bbc.co.uk/2/hi/technology/8182003.stm Call for debate on killer robots], By Jason Palmer, Science and technology reporter, BBC News, 8/3/09. </ref> The President of the AAAI has commissioned a study to look at this issue.<ref> [http://research.microsoft.com/en-us/um/people/horvitz/AAAI_Presidential_Panel_2008-2009.htm AAAI Presidential Panel on Long-Term AI Futures 2008-2009 Study], Association for the Advancement of Artificial Intelligence, Accessed 7/26/09.</ref>

Commenting on Singularity Summit 2010, Patrick Takahashi, director emeritus of the Hawaii Natural Energy Institute, wrote: 

{{quotation|[I]t was refreshing and invigorating for me to experience unbounded optimism at the Singularity Summit gathering in San Francisco this past weekend. Six hundred geeky, bright and mostly young participants sat in on two days of hope for the future. Many of us are familiar with the term singularity with respect to mathematics and space. However, when applied to humanity, as coined by Vernor Vinge in 1993 and popularized by Ray Kurzweil, exponential advancements in computing and biological sequencing could result in artificial intelligence becoming smarter than humans only in two decades. The overwhelming consensus was that singularity was the solution. This combination of fusion, cloning and artificial genius gifted with humanitarian traits offers not only hope, but certainty that we will not only survive, but thrive.<ref name="Takahashi 2010">{{cite paper| author = Takahashi, Patrick | title = The Singularity Summit 2010 | year = 2010 | url = http://www.huffingtonpost.com/patrick-takahashi/the-singularity-summit-20_b_685196.html2 | accessdate=2010-12-19}}</ref>}}

==Criticism==

Often ridiculing the Singularity as "the [[Rapture]] of the [[Nerd]]s", some critics have dismissed Singularitarianism as [[technological utopianism]] turned into a [[new religious movement]].<ref name="Horgan 2008"/> Science journalist [[John Horgan (American journalist)|John Horgan]] wrote:   

{{quotation|'''Let's face it.''' The singularity is a religious rather than a scientific vision. The science-fiction writer Ken MacLeod has dubbed it ”the rapture for nerds,” an allusion to the end-time, when Jesus whisks the faithful to heaven and leaves us sinners behind. Such yearning for transcendence, whether spiritual or technological, is all too understandable. Both as individuals and as a species, we face deadly serious problems, including terrorism, nuclear proliferation, overpopulation, poverty, famine, environmental degradation, climate change, resource depletion, and AIDS. Engineers and scientists should be helping us face the world's problems and find solutions to them, rather than indulging in escapist, pseudoscientific fantasies like the singularity.<ref name="Horgan 2008"/>}}

David Correia, a professor of [[science and technology studies]] at the University of New Mexico, warns that the interest in the Singularity by corporate and military interests provides a clue as to the direction and social implication of [[transhumanism|transhumanist]] technology:

{{quotation|The singularity movement is encouraged and sponsored by a malevolent coterie of military and corporate interests in search of a technotranscendence that serves to reinforce inequality rather than the dream of human transcendence. Those who should be offering skepticism are blinded, it seems, by the truth claims and seemingly self-evident goodness of technoscience. But the singularity movement is far from progressive and the appealing possibility of technosolutions to our most intractable social and environmental issues masks frightening social and ecological implications ... The Singularity does not anticipate human liberation but offers the conditions of permanent capitalist social relations and the bioengineering of bourgeois values. The singularity movement is old-fashioned eugenics with better techniques passing itself off as pragmatic postmodernism.<ref name="Correia 2010"/>}}

Alarmed by Singularitarian ambitions, some [[green anarchism|green anarchist]] militants have called for violent [[direct action]] to "stop the Singularity".<ref name="Green Anarchy 2005"/> A contributor to ''[[Green Anarchy]]'', an [[anarcho-primitivism|anti-civilization]] journal of theory and action, wrote:

{{quotation|If it is evolutionary for some humans to use intelligence to design and manufacture 'superior' intelligent replacements -- sickening and killing humans alongside other species in the process -- then perhaps they must do their/God's work. But, if their evolution concept is correct, than we, the [...] resistants, have evolved -- well, quite differently. We find all apocalyptic priests and their followers -- bent on destroying us and the rest of the living, breathing 'natural' world -- abominations. Therefore, it is in our 'nature' to do whatever we deem necessary for the survival of our unenhanced selves, our offspring, and our nonhuman relations. We choose life on OUR terms, not on the misanthropic terms of the Masters. A few words from Thoreau have a particular potency in this technophilic society, "for every 100 people chopping at the branches, only one is hacking at the roots". And so it is that we find ourselves, quite 'naturally' -- blade in hand.<ref name="Green Anarchy 2005"/>}}

==See also==
* [[Matrioshka brain]]
* [[Nanorobotics]]
* [[Post scarcity]]
* [[Seed AI]]
* [[Strong AI]]
* [[Technological Singularity]]
* [[Transhumanism]]

==References==
{{Reflist}}

== External links ==
* [http://www.singinst.org/why-singularity.html Why Work Towards the Singularity?] by Eliezer Yudkowsky
* [http://www.nickbostrom.com/ethics/ai.html Ethical Issues in Advanced Artificial Intelligence] by Nick Bostrom

[[Category:Singularitarianism| ]]
[[Category:Anticipatory thinking]]
[[Category:Futurology]]
[[Category:Prediction]]
[[Category:Philosophy of artificial intelligence]]
[[Category:Technology forecasting]]
[[Category:Technology neologisms]]
[[Category:Transhumanism]]


[[it:Singolaritanismo]]
[[lt:Singuliaritarianizmas]]</body> </html>