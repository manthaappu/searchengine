<html> <head> <title>Synchronization (computer science)</title></head><body>In [[computer science]], '''synchronization''' refers to one of two distinct but related concepts: synchronization of [[process (computer science)|processes]], and synchronization of data. '''Process synchronization''' refers to the idea that multiple processes are to join up or handshake at a certain point, so as to reach an agreement or commit to a certain sequence of action. '''Data synchronization''' refers to the idea of keeping multiple copies of a dataset in coherence with one another, or to maintain data integrity. Process synchronization primitives are commonly used to implement data synchronization.

==Process synchronization==
Process synchronization or serialization, strictly defined, is the application of particular mechanisms to ensure that two concurrently-executing [[thread (computer science)|threads]] or [[process (computer science)|processes]] do not execute specific portions of a program at the same time.  If one process has begun to execute a serialized portion of the program, any other process trying to execute this portion must wait until the first process finishes.  Synchronization is used to control access to state both in small-scale multiprocessing systems -- in multithreaded and multiprocessor computers -- and in distributed computers consisting of thousands of units -- in banking and database systems, in web servers, and so on.

===See===
* [[Lock (computer science)]] and [[Mutex]]
* [[Monitor (computer science)]]
* [[Semaphore (programming)]]
* [[Test-and-set]]

==Data synchronization==
{{main|Data synchronization}}

A distinctly different (but related) concept is that of '''data synchronization'''. This refers to the need to keep multiple copies of a set of data coherent with one another. 

Examples include:
* [[File synchronization]], such as syncing a hand-held MP3 player to a desktop computer.
* [[Cluster file system]]s, which are [[file system]]s that maintain data or indexes in a coherent fashion across a whole [[computing cluster]].
* [[Cache coherency]], maintaining multiple copies of data in sync across multiple [[cache]]s.
* [[RAID]], where data is written in a redundant fashion across multiple disks, so that the loss of any one disk does not lead to a loss of data.
* [[Database replication]], where copies of data on a [[database]] are kept in sync, despite possible large geographical separation.
* [[Journaling file system|Journalling]], a technique used by many modern file systems to make sure that file metadata are updated on a disk in a coherent, consistent manner.

==Mathematical foundations==
An abstract mathematical foundation for synchronization primitives is given by the [[history monoid]]. There are also many higher-level theoretical devices, such as [[process calculi]] and [[Petri net]]s, which can be built on top of the history monoid.

== External links ==
*[http://www.ibm.com/developerworks/linux/library/l-linux-synchronization.html Anatomy of Linux synchronization methods] at IBM developerWorks
*[http://greenteapress.com/semaphores/ ''The Little Book of Semaphores''], by Allen B. Downey
{{Parallel_computing}}

[[Category:Concurrency]]
[[Category:Communication]]

[[ar:تزامن (حوسبة)]]
[[de:Prozesssynchronisation]]
[[fr:Synchronisation (multitâches)]]
[[it:Sincronizzazione]]
[[he:סנכרון (מדעי המחשב)]]
[[ja:同期 (計算機科学)]]
[[pt:Sincronização]]
[[ru:Синхронизация (информатика)]]
[[simple:Synchronization (computer science)]]
[[uk:Синхронізація процесів]]</body> </html>