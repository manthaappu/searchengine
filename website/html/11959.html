<html> <head> <title>Elias Bassalygo bound</title></head><body>{{multiple issues|cleanup=May 2010|confusing=May 2010|sections=May 2010|tone=May 2010|unreferenced=May 2010|orphan=December 2010|expert = May 2010}}

Let <math>C</math> be a <math>q</math>-ary code of length <math>n</math>, i.e. a subset of <math>[q]^n</math>.  Let <math>R</math> be the ''rate'' of <math>C</math> and <math>\delta</math> be the ''relative distance''.   

Let <math>B_q(\boldsymbol{y}, \rho n) =\{ \boldsymbol{x} \in [q]^n | \Delta(\boldsymbol{x}, \boldsymbol{y}) \le \rho n \}</math> be the ''Hamming Ball'' of radius <math> \rho n </math> centered at <math>\boldsymbol{y}</math>.  Let <math> Vol_q(\boldsymbol{y}, \rho n) = |B_q(\boldsymbol{y}, \rho n)| </math> be the ''volume'' of the Hamming ball of radius <math> \rho n </math>.  It is obvious that the volume of a Hamming Ball is translation invariant, i.e. irrelevant with position of </math>\boldsymbol{y}</math>.  In particular, <math>B_q(\boldsymbol{y}, \rho n) =B_q(\boldsymbol{0}, \rho n) </math>

With large enough <math>n</math>, the ''rate'' <math>R</math> and  the ''relative distance''<math>\delta</math> satisfies the '''''Elias-Bassalygo bound''''': <math>R \le 1 - H_q( J_q(\delta))+o(1) </math>  

where

: <math> H_q(x)\equiv_\text{def} -x\cdot\log_q{x \over {q-1}}-(1-x)\cdot\log_q{(1-x)} </math>

is the ''q''-ary entropy function
and 

: <math>J_q(\delta) \equiv_\text{def} \left(1-{1\over q}\right)\left(1-\sqrt{1-{q \delta \over{q-1}}}\right) </math> is a function related with [[Johnson bound]]

To prove the Elias–Bassalygo bound, we'll need the following Lemma:
----
'''''Lemma 1''''': Given a ''q''-ary code, <math>C\subseteq  [q]^n </math> and <math> 0\le  e\le  n</math>, there exists a Hamming ball of radius <math>e</math> with at least <math>{|C|Vol_q(0,e)} \over {q^n}</math> codewords in it.

Proof of Lemma 1: We prove ''Lemma 1'' using probability method. Let's random pick a received word <math>y \in [q]^n</math>. The expected size of overlapped region between <math> C</math> and the Hamming ball centered at <math>y</math> with radius <math>e</math>, <math>|B_q(y,e) \cap C|</math> is <math>Vol_q(y,e) {{|C|} \over {q^n}}</math> since <math>y</math> is (uniform) randomly selected. Since this is the expected value of the size, there must exist at least one <math>y</math> such that <math>|B_q(y,e) \cap C| \ge Vol_q(y,e) {{|C|} \over {q^n}} = {{|C|Vol_q(0,e)} \over {q^n}}</math>, otherwise the expectation must be smaller than this value.

----

Now we prove the Elias–Bassalygo bound.

Define <math>e = n J_q(\delta)-1 </math>. 

By Lemma 1, there exists a Hamming ball with <math>B</math> codewords such that 
<math>B\ge { {|C|Vol(0,e)} \over {q^n}} </math>

By [[Johnson bound|Johnson Bound Johnson bound]], we have <math>B\le qdn</math>. Thus,  

<math>\mid C \mid \le qnd \cdot {{q^n} \over {Vol_q(0,e)}} \le q^{n(1-H_q(J_q(\delta))+o(1))}</math>

The second inequality follows from lower bound on the volume of a Hamming ball:
<math> Vol_q(0, \lfloor {{d-1} \over 2} \rfloor) \le q^{H_q({\delta \over 2})n-o(n)} </math>

Putting in <math>d=2e+1</math> and <math> \delta = {d \over n}</math> gives the second inequality.

Therefore we have

: <math>R={\log_q{|C|} \over n} \le 1-H_q(J_q(\delta))+o(1) </math>

== See also ==

* [[Singleton bound]]
* [[Hamming bound]]
* [[Plotkin bound]]
* [[Gilbert–Varshamov bound]]
* [[Johnson bound]]

[[Category:Coding theory]]
[[Category:Articles containing proofs]]</body> </html>