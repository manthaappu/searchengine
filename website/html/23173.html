<html> <head> <title>Machine translation</title></head><body>{{Refimprove|date=June 2008}}
{{Navbox translation}}
<!-- PLEASE DO NOT CONVERT REFERENCES WITHOUT DISCUSSING ON TALK PAGE. SEE http://bugzilla.wikimedia.org/show_bug.cgi?id=5885 -->
'''Machine translation''', sometimes referred to by the abbreviation '''MT''', also called [[Computer-assisted_translation|'''computer-aided translation''']], '''machine-aided human translation''' '''MAHT''' and '''interactive translation''', is a sub-field of [[computational linguistics]] that investigates the use of [[computer software]] to [[translation|translate]] text or speech from one [[natural language]] to another.

At its basic level, MT performs simple [[substitution]] of words in one natural language for words in another, but that alone usually cannot produce a good translation of a text, because recognition of whole phrases and their closest counterparts in the target language is needed. Solving this problem with [[corpus linguistics|corpus]] and [[statistics|statistical]] techniques is a rapidly growing field that is leading to better translations, handling differences in [[linguistic typology]], translation of [[idiom]]s, and the isolation of anomalies.{{Citation needed|date=February 2010}}

Current machine translation software often allows for customisation by domain or [[profession]] (such as [[meteorology|weather reports]]), improving output by limiting the scope of allowable substitutions. This technique is particularly effective in domains where formal or formulaic language is used. It follows that machine translation of government and legal documents more readily produces usable output than conversation or less standardised text.

Improved output quality can also be achieved by human intervention: for example, some systems are able to translate more accurately if the user has [[word sense disambiguation|unambiguously identified]] which words in the text are names. With the assistance of these techniques, MT has proven useful as a tool to assist human translators and, in a very limited number of cases, can even produce output that can be used as is (e.g., weather reports).

The progress and potential of machine translation has been debated much through its history. Since the 1950s, a number of scholars has questioned the possibility of achieving fully automatic machine translation of high quality.<ref>First and most notably Bar-Hillel, Yeheshua: "A demonstration of the nonfeasibility of fully automatic high quality machine translation", in ''Language and Information: Selected essays on their theory and application'' (Jerusalem Academic Press, 1964), pp. 174–179.</ref> Some critics claim that there are in-principle obstacles to automatizing the translation process.<ref>[https://docs.google.com/fileview?id=0B7-4xydn3MXJZjFkZTllZjItN2Q5Ny00YmUxLWEzODItNTYyMjhlNTY5NWIz Madsen, Mathias: The Limits of Machine Translation (2010)]</ref>

==History==
{{Main|History of machine translation}}
The idea of machine translation may be traced back to the 17th century. In 1629, [[René Descartes]] proposed a universal language, with equivalent ideas in different tongues sharing one symbol. In the 1950s, The [[Georgetown-IBM experiment|Georgetown experiment]] (1954) involved fully-automatic translation of over sixty [[Russian language|Russian]] sentences into [[English language|English]]. The experiment was a great success and ushered in an era of substantial funding for machine-translation research. The authors claimed that within three to five years, machine translation would be a solved problem. 

Real progress was much slower, however, and after the [[ALPAC|ALPAC report]] (1966), which found that the ten-year-long research had failed to fulfill expectations, funding was greatly reduced. Beginning in the late 1980s, as [[computation]]al power increased and became less expensive, more interest was shown in [[statistical machine translation|statistical models for machine translation]].

The idea of using digital computers for translation of natural languages was proposed as early as 1946 by [[Andrew Donald Booth|A. D. Booth]] and possibly others.  The Georgetown experiment was by no means the first such application, and a demonstration was made in 1954 on the [[APEXC]] machine at [[Birkbeck, University of London|Birkbeck College]] ([[University of London]]) of a rudimentary translation of English into French. Several papers on the topic were published at the time, and even articles in popular journals (see for example ''[[Wireless World]]'', Sept. 1955, Cleave and Zacharov).  A similar application, also pioneered at Birkbeck College at the time, was reading and composing [[Braille]] texts by computer.

==Translation process==
{{Main|Translation process}}
The [[translation process]] may be stated as:
# [[Decoding]] the [[meaning (linguistic)|meaning]] of the [[source text]]; and
# Re-[[encoding]] this [[meaning (linguistic)|meaning]] in the [[target language]].

Behind this ostensibly simple procedure lies a complex [[cognitive]] operation.  To decode the meaning of the [[source text]] in its entirety, the translator must interpret and analyse all the features of the text, a process that requires in-depth knowledge of the [[grammar]], [[semantics]], [[syntax]], [[idiom]]s, etc., of the [[source language]], as well as the [[culture]] of its speakers. The translator needs the same in-depth knowledge to re-encode the meaning in the [[target language]].

Therein lies the challenge in machine translation: how to program a computer that will "understand" a text as a person does, and that will "create" a new text in the [[target language]] that "sounds" as if it has been written by a person.

This problem may be approached in a number of ways.

==Approaches==
[[File:Direct translation and transfer translation pyramind.svg|thumb|right|300px|Pyramid showing comparative depths of intermediary representation, [[interlingual machine translation]] at the peak, followed by transfer-based, then direct translation.]]
Machine translation can use a method based on [[Expert System|linguistic rules]], which means that words will be translated in a linguistic way &mdash; the most suitable (orally speaking) words of the target language will replace the ones in the source language.

It is often argued that the success of machine translation requires the problem of [[natural language processing|natural language understanding]] to be solved first.

Generally, rule-based methods parse a text, usually creating an intermediary, symbolic representation, from which the text in the target language is generated. According to the nature of the intermediary representation, an approach is described as [[interlingual machine translation]] or [[transfer-based machine translation]]. These methods require extensive [[lexicon]]s with [[morphology (linguistics)|morphological]], [[syntax|syntactic]], and [[semantics|semantic]] information, and large sets of rules.

Given enough data, machine translation programs often work well enough for a [[native speaker]] of one language to get the approximate meaning of what is written by the other native speaker. The difficulty is getting enough data of the right kind to support the particular method. For example, the large multilingual [[Text corpus|corpus]] of data needed for statistical methods to work is not necessary for the grammar-based methods. But then, the grammar methods need a skilled linguist to carefully design the grammar that they use.

To translate between closely related languages, a technique referred to as [[shallow-transfer machine translation]] may be used.

===Rule-based===
The rule-based machine translation paradigm includes transfer-based machine translation, interlingual machine translation and dictionary-based machine translation paradigms.
{{Main|Rule-based machine translation}}

'''''Transfer-based machine translation'''''
{{Main|Transfer-based machine translation}}

'''''Interlingual'''''
{{Main|Interlingual machine translation}}

Interlingual machine translation is one instance of rule-based machine-translation approaches.  In  this approach, the source language, i.e. the text to be translated, is transformed into an interlingual, i.e. source-/target-language-independent representation. The target language is then generated out of the [[interlinguistics|interlingua]].

'''''Dictionary-based'''''
{{Main|Dictionary-based machine translation}}

Machine translation can use a method based on [[dictionary]] entries, which means that the words will be translated as they are by a dictionary.

===Statistical===
{{Main|Statistical machine translation}}

Statistical machine translation tries to generate translations using [[statistical methods]] based on bilingual text corpora, such as the [[Hansard#Machine translation|Canadian Hansard]] corpus, the English-French record of the Canadian parliament and [[EUROPARL]], the record of the [[European Parliament]]. Where such corpora are available, impressive results can be achieved translating texts of a similar kind, but such corpora are still very rare. The first statistical machine translation software was [[CANDIDE]] from [[IBM]].  Google used [[SYSTRAN]] for several years, but switched to a statistical translation method in October 2007.  Recently, they improved their translation capabilities by inputting 
approximately 200 billion words from [[United Nations]] materials to train their system.  Accuracy of the translation has improved.<ref>[http://blog.outer-court.com/archive/2005-05-22-n83.html Google Translator: The Universal Language<!-- Bot generated title -->]</ref>

===Example-based===
{{Main|Example-based machine translation}}

Example-based machine translation (EBMT) approach was proposed by [[Makoto Nagao]] in 1984.<ref>Nagao, M. 1981. A Framework of a Mechanical Translation between Japanese and English by Analogy Principle, in Artificial and Human Intelligence, A. Elithorn and R. Banerji (eds.) North- Holland, pp. 173-180, 1984.</ref><ref>{{Cite web | url = http://www.aclweb.org/index.php?option=com_content&task=view&id=36&Itemid=30 | title = the Association for Computational Linguistics - 2003 ACL Lifetime Achievement Award | publisher = Association for Computational Linguistics | accessdate = 2010-03-10}}</ref> It is often characterised by its use of a bilingual [[Text corpus|corpus]] as its main knowledge base, at run-time. It is essentially a translation by [[analogy]] and can be viewed as an implementation of [[case-based reasoning]] approach of [[machine learning]].

===Hybrid MT===

Hybrid machine translation (HMT) leverages the strengths of statistical and rule-based translation methodologies.<ref name="speechtechmag.com">[http://www.speechtechmag.com/Articles/News/News-Feature/AppTek-Launches-Hybrid-Machine-Translation-Software-52871.aspx Boretz, Adam, "AppTek Launches Hybrid Machine Translation Software" SpeechTechMag.com (posted 2 MAR 2009) ]</ref> Several MT companies ([[Asia Online]], LinguaSys, [[Systran]], [[Polytechnic_University_of_Valencia|UPV]]) are claiming to have a hybrid approach using both rules and statistics. The approaches differ in a number of ways:
* '''Rules post-processed by statistics''': Translations are performed using a rules based engine. Statistics are then used in an attempt to adjust/correct the output from the rules engine.
* '''Statistics guided by rules''': Rules are used to pre-process data in an attempt to better guide the statistical engine. Rules are also used to post-process the statistical output to perform functions such as normalization. This approach has a lot more power, flexibility and control when translating.

==Major issues==
===Disambiguation===
{{Main|Word sense disambiguation}}
Word-sense disambiguation concerns finding a suitable translation when a word can have more than one meaning. The problem was first raised in the 1950s by [[Yehoshua Bar-Hillel]].<ref>[http://ourworld.compuserve.com/homepages/WJHutchins/Miles-6.htm Milestones in machine translation - No.6: Bar-Hillel and the nonfeasibility of FAHQT] by John Hutchins</ref> He pointed out that without a "universal encyclopedia", a machine would never be able to distinguish between the two meanings of a word.<ref>Bar-Hillel (1960), "Automatic Translation of Languages". Available online at http://www.mt-archive.info/Bar-Hillel-1960.pdf</ref> Today there are numerous approaches designed to overcome this problem. They can be approximately divided into "shallow" approaches and "deep" approaches. 

Shallow approaches assume no knowledge of the text. They simply apply statistical methods to the words surrounding the ambiguous word. Deep approaches presume a comprehensive knowledge of the word. So far, shallow approaches have been more successful. {{Citation needed|date=April 2007}}

The late [[Claude Piron]], a long-time translator for the [[United Nations]] and the [[World Health Organization]], wrote that machine translation, at its best, automates the easier part of a translator's job; the harder and more time-consuming part usually involves doing extensive research to resolve [[ambiguity|ambiguities]] in the [[source text]], which the [[grammatical]] and [[lexical]] exigencies of the [[target language]] require to be resolved:

: Why does a translator need a whole workday to translate five pages, and not an hour or two? ..... About 90% of an average text corresponds to these simple conditions.  But unfortunately, there's the other 10%.  It's that part that requires six [more] hours of work.  There are ambiguities one has to resolve.  For instance, the author of the source text, an Australian physician, cited the example of an epidemic which was declared during World War II in a "Japanese prisoner of war camp".  Was he talking about an American camp with Japanese prisoners or a Japanese camp with American prisoners?  The English has two senses.  It's necessary therefore to do research, maybe to the extent of a phone call to Australia.<ref name="piron">[[Claude Piron]], ''Le défi des langues'' (The Language Challenge), Paris, L'Harmattan, 1994. <!-- GFDL translation by Jim Henry --></ref>

The ideal deep approach would require the translation software to do all the research necessary for this kind of disambiguation on its own; but this would require a higher degree of [[AI]] than has yet been attained.  A shallow approach which simply guessed at the sense of the ambiguous English phrase that Piron mentions (based, perhaps, on which kind of prisoner-of-war camp is more often mentioned in a given corpus) would have a reasonable chance of guessing wrong fairly often.  A shallow approach that involves "ask the user about each ambiguity" would, by Piron's estimate, only automate about 25% of a professional translator's job, leaving the harder 75% still to be done by a human.

===Named entities===
{{Expand section|date=January 2010}}
Related to [[named entity recognition]] in [[information extraction]].

==Applications==
There are now many [[software]] programs for translating natural language, several of them [[online]], such as:
*[[Ta with you]] [http://www.tauyou.com] is specialized in customized machine translation solutions in any language. Their web-based user interface makes it easy for any Language Service Provider to generate any combination of domain and language pair to achieve the best quality. Their solution works with almost human quality for combinations from/to Spanish. 
*[[LinguaSys]] [http://www.linguasys.net] provides highly customized hybrid machine translation that can go from any language to any language.
*[[Asia Online]][http://www.asiaonline.net] provides a custom machine translation engine building capability that they claim gives near-human quality compared to the "gist" based quality of free online engines. [[Asia Online]] also provides tools to edit and create custom machine translation engines with their [http://www.languagestudio.com Language Studio] suite of products.
*[[Hindi to Punjabi Machine Translation System]][http://h2p.learnpunjabi.org], provides machine translation using a direct approach. It translates Hindi into Punjabi. It also features writing e-mail in the Hindi language and sending the same in Punjabi to the recipient.
* [https://sites.google.com/site/khaledshaalan/publications/journal-papers/Generating_Arabic_MT_journal.zip?attredirects=0 Arabic machine translation] in multilingual framework.
*[[Worldlingo]] provides machine translation using both statistical based TE's and rule based TE's. Most recognizable as the MT partner in Microsoft Windows and [[Microsoft Office 2008 for Mac|Microsoft Mac Office]].
*[[Power Translator]]
*[[SDL ETS]] and [[Language Weaver|SDL Language Weaver]] which power [[FreeTranslation.com (website)]]
*[[SYSTRAN]], which powers [[Yahoo! Babel Fish]]
*[[Promt]], which powers online translation services at Voila.fr and Orange.fr
*[[Apptek|AppTek]], which released a hybrid MT system in 2009.<ref name="speechtechmag.com"/>
*[[IdiomaX]], which powers online translation services at idiomax.com
*[[Toggletext]] uses a transfer-based system (known as Kataku) to translate between [[English language|English]] and [[Indonesian language|Indonesian]].
*[[Anusaaraka]] A free open source machine translation from English to Hindi based on Panini grammar and uses state of the art NLP tools. Can be used online and downloaded from [http://anusaaraka.iiit.ac.in]
*[[Apertium]], a free and open source machine translation platform ([http://www.winxlator.com WinXLator] gives this a [[Windows]] GUI, but it is likely to be in violation of the Apertium GPL license)
*[[Google Translate]] A free online translator from [[Google]].
Other translation software, most of them running under [[Microsoft Windows]], includes 
*[[Translation memory]] tools, such as [[Globalsight]], [[SDL]] [[Trados]], [[Wordfast]], [[Deja Vu (software)|Deja Vu]], [http://www.maxprograms.com/products/swordfish.html Swordfish], and
*[[Internationalization and localization|localization tools]], such and [[Alchemy]] CATALYST and [http://www.multilizer.com Multilizer].
*[http://sishitra.iti.upv.es/ SiShiTra] &mdash; A hybrid machine translation engine for Spanish-Catalan translation.

(A comparison test of software of this kind may be seen [http://translation-software-review.toptenreviews.com/ here].) A number of translation software programs are available free of charge, e.g. [http://sourceforge.net/projects/foreigndesk/ ForeignDesk] and the multiplatform [[Okapi Framework]]<ref>[http://code.google.com/p/okapi/ Okapi Framework website]</ref> and [http://omegatplus.sourceforge.net/ OmegaT+]. 

While no system provides the holy grail of fully-automatic high-quality machine translation of unrestricted text, many fully-automated systems produce reasonable output.<ref>[http://www.benjamins.com/cgi-bin/t_bookview.cgi?bookid=BTL%2014 Melby, Alan. The Possibility of Language (Amsterdam:Benjamins, 1995, 27-41)]</ref><ref>[http://tandibusiness.blogspot.com/2006/02/simple-model-outlining-translation.html Wooten, Adam. "A Simple Model Outlining Translation Technology" T&I Business (February 14, 2006)]</ref><ref>[http://www.mt-archive.info/Bar-Hillel-1960-App3.pdf Appendix III of 'The present status of automatic translation of languages', Advances in Computers, vol.1 (1960), p.158-163. Reprinted in Y.Bar-Hillel: Language and information (Reading, Mass.: Addison-Wesley, 1964), p.174-179.]</ref> The quality of machine translation is substantially improved if the domain is restricted and controlled.<ref>[http://tauyou.com/blog/?p=47 Human quality machine translation solution by Ta with you]</ref>

Despite their inherent limitations, MT programs are used around the world. Probably the largest institutional user is the [[European Commission]]. The [[MOLTO]] project, for example, coordinated by the [[University of Gothenburg]], received more than 2.375 million euros project support from the EU to create a reliable translation tool that covers a majority of the EU languages.[http://www.molto-project.eu/]

[[Google]] has claimed that promising results were obtained using a proprietary statistical machine translation engine.<ref>[http://googleblog.blogspot.com/2005/08/machines-do-translating.html Google Blog: The machines do the translating] (by [[Franz Och]])</ref> The statistical translation engine used in the [[Google tools#anchor_language_tools|Google language tools]] for Arabic <-> English and Chinese <-> English had an overall score of 0.4281 over the runner-up IBM's BLEU-4 score of 0.3954 (Summer 2006) in tests conducted by the National Institute for Standards and Technology.<ref>[http://ieeexplore.ieee.org/iel5/2/32474/01516048.pdf?arnumber=1516048 Geer, David, "Statistical Translation Gains Respect", pp. 18 - 21, IEEE Computer, October 2005]</ref><ref>[http://www.wired.com/wired/archive/14.12/translate.html Ratcliff, Evan "Me Translate Pretty One Day", Wired December 2006]</ref><ref>[http://www.itl.nist.gov/iad/mig//tests/mt/2006/doc/mt06eval_official_results.html_official_results.html "NIST 2006 Machine Translation Evaluation Official Results", November 1, 2006]</ref>

With the recent focus on terrorism, the military sources in the United States have been investing significant amounts of money in natural language engineering. ''In-Q-Tel''<ref>[http://www.in-q-tel.com In-Q-Tel]</ref> (a [[venture capital]] fund, largely funded by the US Intelligence Community, to stimulate new technologies through private sector entrepreneurs) brought up companies like [[Language Weaver]]. Currently the military community is interested in translation and processing of languages like [[Arabic language|Arabic]], [[Pashto language|Pashto]], and [[Dari language|Dari]]. {{Citation needed|date=February 2007}} The Information Processing Technology Office in [[DARPA]] hosts programs like [[DARPA TIDES program|TIDES]] and [[Babylon translator|Babylon Translator]]. US Air Force has awarded a $1 million contract to develop a language translation technology.<ref>[http://gcn.com/articles/2003/09/09/air-force-wants-to-build-a-universal-translator.aspx GCN &mdash; Air force wants to build a universal translator]</ref>

The notable rise of [[social networking]] on the web in recent years has created yet another niche for the application of machine translation software – in utilities such as Facebook, or [[instant messaging]] clients such as Skype, GoogleTalk, MSN Messenger, etc. – allowing users speaking different languages to communicate with each other. Machine translation applications have also been released for most mobile devices, including mobile telephones, pocket PCs, PDAs, etc. Due to their portability, such instruments have come to be designated as [[mobile translation]] tools enabling mobile business networking between partners speaking different languages, or facilitating both foreign language learning and unaccompanied traveling to foreign countries without the need of the intermediation of a human translator.

== Evaluation ==
{{Main|Evaluation of machine translation}}
Machine translation systems and output can be evaluated along numerous dimensions. The intended use of the translation, characteristics of the MT software, the nature of the translation process, etc., all affect how one evaluates MT systems and their output. The FEMTI taxonomy of dimensions, with associated evaluation metrics, appears at http://www.issco.unige.ch:8080/cocoon/femti/st-home.html .  

There are various means for evaluating the output quality of machine translation systems. The oldest is the use of human judges<ref>[http://www.morphologic.hu/public/mt/2008/compare12.htm Comparison of MT systems by human evaluation, May 2008]</ref> to assess a translation's quality. Even though human evaluation is time-consuming, it is still the most reliable way to compare different systems such as rule-based and statistical systems. [[Automate]]d means of evaluation include [[Bilingual evaluation understudy|BLEU]], [[NIST (metric)|NIST]] and [[METEOR]].

Relying exclusively on unedited machine translation ignores the fact that communication in [[natural language|human language]] is [[wikt:context|context]]-embedded and that it takes a person to comprehend the context of the original text with a reasonable degree of probability. It is certainly true that even purely human-generated translations are prone to error. Therefore, to ensure that a machine-generated translation will be useful to a human being and that publishable-quality translation is achieved, such translations must be reviewed and edited by a human.<ref>J.M. Cohen observes (p.14): "Scientific translation is the aim of an age that would reduce all activities to [[Technology|techniques]]. It is impossible however to imagine a literary-translation machine less complex than the human brain itself, with all its knowledge, reading, and discrimination."</ref> The late [[Claude Piron]] wrote that machine translation, at its best, automates the easier part of a translator's job; the harder and more time-consuming part usually involves doing extensive research to resolve [[ambiguity|ambiguities]] in the [[source text]], which the [[grammatical]] and [[lexical]] exigencies of the target language require to be resolved.<ref name="piron" /> Such research is a necessary prelude to the pre-editing necessary in order to provide input for machine-translation software such that the output will not be [[garbage in garbage out|meaningless]].<ref name="NIST">See the [http://www.nist.gov/speech/tests/mt/ annually performed NIST tests since 2001] and [[Bilingual Evaluation Understudy]]</ref>

In certain applications, however, e.g., product descriptions written in a [[controlled language]], a [[dictionary-based machine translation|dictionary-based machine-translation]] system has produced satisfactory translations that require no human intervention save for quality inspection.<ref>Muegge (2006), "Fully Automatic High Quality Machine Translation of Restricted Text: A Case Study," in ''Translating and the computer 28. Proceedings of the twenty-eighth international conference on translating and the computer, 16–17 November 2006, London'', London: Aslib. ISBN 978-0-85142-483-5.</ref>

== See also ==
* [[Comparison of Machine translation applications]]
* [[Artificial Intelligence]]
* [[Computational linguistics]]
* [[Universal Networking Language]]
* [[Computer-assisted translation]] and [[Translation memory]]
* [[Controlled natural language]]
* [[Fuzzy matching]]
* [[Postediting]]
* [[History of machine translation]]
* [[Human Language Technology]]
* [[Language barrier]]
* [[List of emerging technologies]]
* [[List of research laboratories for machine translation]]
* [[Pseudo-translation]]
* [[Translation]]
* [[Translation memory]]
* [[Universal translator]]
* [[Phraselator]]
* [[Mobile translation]]

==Notes==
{{reflist|2}}

==References==
* Cohen, J.M., "Translation", ''[[Encyclopedia Americana]]'', 1986, vol. 27, pp. 12–15.
*{{cite book | last = Hutchins | first = W. John | authorlink = John Hutchins | coauthors = and Harold L. Somers | year = 1992 | title = An Introduction to Machine Translation | url = http://www.hutchinsweb.me.uk/IntroMT-TOC.htm | publisher = Academic Press | location = London | isbn = 0-12-362830-X}}
*[[Claude Piron]], ''Le défi des langues — Du gâchis au bon sens'' (The Language Challenge:  From Chaos to Common Sense), Paris, L'Harmattan, 1994.

== External links==
{{Wikiversity|Topic:Computational linguistics}}
* [http://www.statmt.org/ Statistical Machine Translation]
* [http://www.eamt.org/iamt.php International Association for Machine Translation (IAMT)]
*[http://www.mt-archive.info Machine Translation Archive] by [[John Hutchins]]. An electronic repository (and bibliography) of articles, books and papers in the field of machine translation and computer-based translation technology
*[http://www.hutchinsweb.me.uk/ Machine translation (computer-based translation)] &mdash; Publications by John Hutchins (includes [[PDF format|PDF]]s of several books on machine translation)
*[http://bowland-files.lancs.ac.uk/monkey/ihe/mille/paper2.htm Machine Translation and Minority Languages]
*[http://www.foreignword.com/Technology/art/Hutchins/hutchins99.htm John Hutchins 1999]
*[http://www.chandos.ca/Metrics_for_Evaluating_Translation_Memory_Software.pdf Metrics for Evaluating Translation Memory Software] (an MA thesis by Francie Gow from the School of Translation and Interpretation, [[University of Ottawa]])
* Grace Hui Chin Lin (2010) Machine Translation in Post-Contemporary Era   [http://www.eric.ed.gov/PDFS/ED514031.pdf]
* Grace Hui Chin Lin & Paul Shih Chieh Chien (2009) Machine Translation for Academic Purpose
[http://www.eric.ed.gov/PDFS/ED513879.pdf] 

{{Approaches to machine translation}}

[[Category:Artificial intelligence applications]]
[[Category:Computational linguistics]]
[[Category:Machine translation|*]]
[[Category:Computer-assisted translation]]
[[Category:Tasks of Natural language processing]]

{{Link FA|eu}}

[[af:Outomatiese vertaling]]
[[ar:ترجمة آلية]]
[[be:Машынны пераклад]]
[[be-x-old:Машынны пераклад]]
[[bg:Машинен превод]]
[[ca:Traducció automàtica]]
[[cv:Тăлмач-программа тăлмачлани]]
[[cs:Strojový překlad]]
[[cy:Peiriant cyfieithu]]
[[da:Maskinoversættelse]]
[[de:Maschinelle Übersetzung]]
[[es:Traducción automática]]
[[eo:Maŝintradukado]]
[[eu:Itzulpengintza automatiko]]
[[fa:ترجمه ماشینی]]
[[fr:Traduction automatique]]
[[gl:Tradución automática]]
[[ko:기계 번역]]
[[hi:यांत्रिक अनुवाद]]
[[hr:Strojno prevođenje]]
[[id:Terjemahan mesin]]
[[is:Vélþýðing]]
[[it:Traduzione automatica]]
[[he:תרגום מכונה]]
[[la:Translatio machinalis]]
[[lt:Automatinis vertimas]]
[[hu:Gépi fordítás]]
[[mk:Машинско преведување]]
[[mg:Fandikana ataon'ny milina]]
[[mr:मशिन ट्रान्सलेशन]]
[[ms:Terjemahan mesin]]
[[nl:Computervertaling]]
[[ja:機械翻訳]]
[[no:Maskinoversettelse]]
[[nn:Maskinomsetjing]]
[[oc:Traduccion automatica]]
[[pl:Tłumaczenie automatyczne]]
[[pt:Tradução automática]]
[[ro:Traducere automată]]
[[ru:Машинный перевод]]
[[sc:Tradutzione automàtica]]
[[simple:Machine translation]]
[[sk:Strojový preklad]]
[[sl:Strojno prevajanje]]
[[sr:Машинско превођење]]
[[fi:Konekääntäminen]]
[[sv:Maskinöversättning]]
[[ta:பொறிமுறை மொழிபெயர்ப்பு]]
[[th:การแปลภาษาอัตโนมัติ]]
[[tg:Тарҷумаи мошинӣ]]
[[uk:Машинний переклад]]
[[vi:Dịch tự động]]
[[wuu:机器翻译]]
[[zh-yue:機械翻譯]]
[[zh:机器翻译]]</body> </html>