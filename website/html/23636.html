<html> <head> <title>Massively parallel</title></head><body>'''Massively parallel ''' is a description which appears in computer science, [[life sciences]], [[medical diagnostics]], and other fields.

A '''massively parallel computer''' is a [[distributed memory]] computer system which consists of many individual nodes, each of which is essentially an independent computer in itself, and in turn consists of at least one processor, its own memory, and a link to the network that connects all the nodes together. Such computer systems have many independent [[arithmetic]] units or entire [[microprocessor]]s, that run in parallel. The term ''massive'' connotes hundreds if not thousands of such units. Nodes communicate by passing messages, using standards such as [[Message Passing Interface|MPI]].

In this class of computing, all of the processing elements are connected together to be one very large computer. This is in contrast to [[distributed computing]] where massive numbers of separate computers are used to solve a single problem.  

== Supercomputers ==
Nearly all [[supercomputer]]s as of 2005 are massively parallel, with the largest having several hundred thousand [[central processing unit|CPU]]s. The cumulative output of the many constituent CPUs can result in large total peak FLOPS (FLoating point Operations Per Second) numbers. The true amount of computation accomplished depends in the nature of the computational task and its implementation. Some problems are more intrinsically able to be separated into parallel computational tasks than others. When problems depend on sequential stages of computation, some processors must remain idle while waiting for the result of calculations from other processors, resulting in less efficient performance. The efficient implementation of computational tasks on parallel computers is an active area of research. See also [[Parallel computing]].

Through advances in [[Moore's Law]], single-chip implementations of [[massively parallel processor array]]s are becoming cost effective, and finding particular application in high performance [[embedded systems]] applications such as [[video compression]].  Examples include chips from [[Ambric]], [http://www.coherentlogix.com Coherent Logix], [[Picochip|picoChip]], and [[Tilera]].

== In medicine ==

In  life science and medical diagnostics, '''massively parallel chemical reactions''' are used to reduce the time and cost of an analysis or synthesis procedure, often to provide ultra-high throughput. For example, in ultra-high-throughput DNA sequencing as introduced in August 2005 there may be 500,000 sequencing-by-synthesis operations occurring in parallel.<ref>{{cite book|title=Massively Parallel, Optical, and Neural Computing in the United States|author=Gilbert Kalb, Robert Moxley|publisher=Moxley|year=1992|isbn=9051990979}}</ref>

== Example systems ==

The earliest massively parallel processing systems all used [[serial computer]]s as individual processing elements, in order to achieve the maximum number of independent units for a given size and cost. Some years ago many of the most powerful [[supercomputer]]s were ''MPP'' systems. Early examples of such a system are the [[Distributed Array Processor]] (DAP), the [[Goodyear MPP]], the [[Connection Machine]], and the [[Ultracomputer]].

==See also==
*[[Fifth generation computer systems project]]
*[[Massively parallel processor array]]
*[[Multiprocessing]]
*[[Parallel computing]]
*[[Process oriented programming]]
*[[Shared nothing architecture]] (SN)
*[[Symmetric multiprocessing]] (SMP)

==References==
<references/>

{{Parallel_computing}}

[[Category:Parallel computing]]
[[Category:Massively parallel computers]]

[[ar:حاسوب متوازي هائل]]
[[de:Massively Parallel Processing]]
[[ko:대규모 병렬 컴퓨터]]
[[it:Sistema ad elevato parallelismo]]
[[ja:超並列マシン]]
[[pl:MPP]]
[[ru:Массивно-параллельная архитектура]]
[[uk:Масово-паралельна архітектура]]
[[zh:大规模并行处理机]]</body> </html>