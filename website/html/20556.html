<html> <head> <title>Kernel methods</title></head><body>'''Kernel methods''' (KMs) are a class of algorithms for [[pattern analysis]], whose best known element
is the [[support vector machine]] (SVM). The general task of pattern analysis is to find and study general types of relations (for example [[Cluster analysis|clusters]], [[ranking]]s, [[principal components]], [[correlation]]s, [[Categorization|classification]]s) in general types of data (such as sequences, text documents, sets of points, vectors, images, etc.).

KMs approach the problem by mapping the data into a high dimensional [[feature space]], where each [[coordinate]] corresponds to one feature of the data items, [[data transformation|transforming]] the data into a set of points in a [[Euclidean space]].  In that space, a variety of methods can be used to find relations in the data. Since the mapping can be quite general (not necessarily [[linear]], for example), the relations found in this way are accordingly very general.  This approach is called the [[kernel trick]].

KMs owe their name to the use of [[Kernel (statistics)|kernel function]]s, which enable them to operate in the feature space without ever computing the coordinates of the data in that space, but rather by simply computing the [[inner product]]s between the images of all pairs of data in the feature space.  This operation is often computationally cheaper than the explicit computation of the coordinates.  Kernel functions have been introduced for sequence data, graphs, text, images, as well as vectors.

Algorithms capable of operating with kernels include [[Support vector machine]] (SVM), [[Gaussian process]]es, [[Ronald Fisher|Fisher's]] [[linear discriminant analysis]] (LDA), [[principal components analysis]] (PCA), [[canonical correlation analysis]], [[ridge regression]], [[spectral clustering]], [[Adaptive filter|linear adaptive filters]] and many others.

Because of the particular culture of the research community that has been developing this approach since the mid-1990s, most kernel algorithms are based on [[convex optimization]] or [[Eigenvalue, eigenvector and eigenspace|eigenproblems]], are [[computationally efficient]] and statistically well-founded. Typically, their statistical properties are analyzed using [[statistical learning theory]] (for example, using [[Rademacher complexity]]).

==Applications==

At the moment, the main application areas are in [[geostatistics]], [[kriging]], [[inverse distance weighting]], [[bioinformatics]], [[chemoinformatics]], [[information extraction]], [[text categorization]], and [[handwriting recognition]].

==See also==
[http://onlineprediction.net/?n=Main.KernelMethods onlineprediction.net Kernel Methods Article]

==References==
* [http://www.kernel-machines.org Kernel-Machines Org] -- community website
* [http://www.support-vector-machines.org www.support-vector-machines.org] ''(Literature, Review, Software, Links related to Support Vector Machines - Academic Site)''
* J. Shawe-Taylor and N. Cristianini. ''Kernel Methods for Pattern Analysis.'' Cambridge University Press, 2004.
* W. Liu, J. Principe and S. Haykin. ''Kernel Adaptive Filtering: A Comprehensive Introduction.'' Wiley, 2010.

{{DEFAULTSORT:Kernel Methods}}
[[Category:Machine learning]]
[[Category:Kernel methods for machine learning]]
[[Category:Geostatistics]]
[[Category:Classification algorithms]]

[[ja:カーネル法]]</body> </html>