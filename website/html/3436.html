<html> <head> <title>Basis pursuit denoising</title></head><body>'''Basis pursuit denoising''' is the [[mathematical optimization]] problem of the form:

:<math>\min_x \frac{1}{2}\|y-Ax\|^2_2+\lambda\|x\|_1.</math>

where <math>\lambda</math> is a parameter that controls the trade-off between sparsity and reconstruction fidelity, <math>x</math> is a <math>N \times 1</math> solution vector, <math>y</math> is a <math>M \times 1</math> vector of observations, <math>A</math> is a <math>M \times N</math> transform matrix and <math>M < N</math>.

Basis pursuit denoising solves a [[Regularization (mathematics)|regularization]] problem with a trade-off between having a small residual (making <math>y</math> close to <math>Ax</math> in the <math>L_2</math> sense) and making <math>x</math> simple in the <math>L_1</math> sense.

Exact solutions to basis pursuit denoising are often the best computationally tractable approximation of an underdetermined system of equations.  Basis pursuit denoising thus has potential applications in statistics (c.f. the [[Lasso_(statistics)#LASSO_method|LASSO]] method of [[Regularization (mathematics)|regularization]]), [[image compression]] and [[Compressed sensing]].

When <math>\lambda=0</math>, this problem becomes [[basis pursuit]].

==Solving basis pursuit denoising==

Several popular methods for solving basis pursuit denoising include [[homotopy continuation]], [[fixed-point continuation]] and [[spectral projected gradient for L1 minimization]] (which actually solves [[Lasso_(statistics)#LASSO_method|LASSO]], a related problem).

[[Category:Mathematical optimization]]


{{Mathapplied-stub}}</body> </html>