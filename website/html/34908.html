<html> <head> <title>Soft independent modelling of class analogies</title></head><body>'''Soft independent modelling by class analogy''' (SIMCA) is a [[statistics|statistical]] method for [[Supervised learning|supervised classification]] of data. The method requires a training data set consisting of samples (or objects) with a set of attributes and their class membership. The term soft refers to the fact the classifier can identify samples as belonging to multiple classes and not necessarily producing a classification of samples into non-overlapping classes. 

==Method==
In order to build the classification models, the samples belonging to each class need to be analysed using [[principal components analysis]] (PCA); only the significant components are retained. 

For a given class, the resulting model then describes either a line (for one Principal Component or PC), plane (for two PCs) or hyper-plane (for more than two PCs). For each modelled class, the mean orthogonal distance of training data samples from the line, plane or hyper-plane (calculated as the residual standard deviation) is used to determine a critical distance for classification. This critical distance is based on the [[F-distribution]] and is usually calculated using 95% or 99% confidence intervals.

New observations are projected into each PC model and the residual distances calculated. An observation is assigned to the model class when its residual distance from the model is below the statistical limit for the class. The observation may be found to belong to multiple classes and a measure of [[goodness of fit|goodness of the model]] can be found from the number of cases where the observations are classified into multiple classes. The classification efficiency is usually indicated by [[Receiver operating characteristic]]s.

In the original SIMCA method, the ends of the hyper-plane of each class are closed off by setting statistical control limits along the retained principal components axes (i.e. range: minimum score value minus 0.5 times score standard deviation to maximum score value plus 0.5 times standard deviation).

More recent adaptations of the SIMCA method close off the hyper-plane by construction of ellipsoids (e.g. [[Hotelling's T-square distribution|Hotellings T<sup>2</sup>]] or [[Mahalanobis distance]]). With such modified SIMCA methods, classification of an object requires both that its orthogonal distance from the model and its projection within the model (i.e. score value within region defined by ellipsoid) are not significant.

==Application==
SIMCA as a method of classification has gained widespread use especially in applied statistical fields such as [[chemometrics]] and spectroscopic data analysis.
==References==
* Wold, Svante, and Sjostrom, Michael, 1977, SIMCA: A method for analyzing chemical data in terms of similarity and analogy, in Kowalski, B.R., ed., Chemometrics Theory and Application, American Chemical Society Symposium Series 52, Wash., D.C., American Chemical Society, p. 243-282.

[[Category:Machine learning]]
[[Category:Classification algorithms|*]]</body> </html>