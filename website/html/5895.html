<html> <head> <title>Character (computing)</title></head><body>In [[computer]] and machine-based [[telecommunication]]s terminology, a '''character''' is a unit of [[information]] that roughly corresponds to a [[grapheme]], grapheme-like unit, or symbol, such as in an [[alphabet]] or [[syllabary]] in the [[written language|written]] form of a [[natural language]].

Examples of characters include [[letters]], [[numerical digit]]s, and common [[punctuation]] marks (such as '.' or '-'). The concept also includes [[control character]]s, which do not correspond to symbols in a particular natural language, but rather to other bits of information used to process text in one or more languages. Examples of control characters include [[carriage return]] or [[tab key|tab]], as well as instructions to [[computer printer|printer]]s or other devices that display or otherwise process text.

Characters are typically combined into [[string (computer science)|string]]s.

== Character encoding ==
{{main|Character encoding}}
Computers and communication equipment represent characters using a [[character encoding]] that assigns each character to something — an [[integer]] quantity represented by a sequence of [[bit]]s, typically — that can be [[computer storage|stored]] or transmitted through a [[computer network|network]]. Two examples of popular encodings are [[ASCII]] and the [[UTF-8]] encoding for [[Unicode]].  While most character encodings map characters to numbers and/or bit sequences, [[Morse code]] instead represents characters using a series of electrical impulses of varying length.

== Terminology ==
Historically, the term ''character'' has been widely used by industry professionals to refer to an ''encoded character'', often as defined by the programming language or [[application programming interface|API]]). Likewise, ''character set'' has been widely used to refer to a specific repertoire of characters that have been mapped to specific bit sequences or numerical codes.  The term [[glyph]] is used to describe a particular physical appearance of a character. Many computer [[typeface|font]]s consist of glyphs that are indexed by the numerical code of the corresponding character.

With the advent and widespread acceptance of Unicode<ref name=movingtounicode>{{cite web |url=http://googleblog.blogspot.com/2008/05/moving-to-unicode-51.html |title=Moving to Unicode 5.1 |accessdate=2008-09-28 |last=Davis |first=Mark |work=Google Blog |publisher= |date=2008-05-05 }}</ref> and bit-agnostic ''encoding forms'',{{clarify|date=June 2009}}, a character is increasingly being seen as a unit of [[data|information]], independent of any particular visual manifestation.  The [[Universal Character Set|ISO/IEC 10646 (Unicode) International Standard]] defines ''character'', or ''abstract character'' as "a member of a set of elements used for the organisation, control, or representation of data". Unicode's definition supplements this with explanatory notes that encourage the reader to differentiate between characters, graphemes, and glyphs, among other things.

For example, the [[Hebrew alphabet|Hebrew letter]] [[aleph (letter)|aleph]] ("א") is often used by mathematicians to denote certain kinds of [[Aleph number|infinity]], but it is also used in ordinary Hebrew text. In Unicode, these two uses are considered different characters, and have two different Unicode numerical identifiers ("code points"), though they may be rendered identically. Conversely, the [[Chinese script|Chinese]] [[logogram]] for water ("水") may have a slightly different appearance in [[Japanese script|Japanese]] texts than it does in Chinese texts, and local [[typeface]]s may reflect this. But nonetheless in Unicode they are considered the same character, and share the same code point.

The Unicode standard also differentiates between these abstract characters and ''coded characters'' or ''encoded characters'' that have been paired with numeric codes that facilitate their representation in computers.

== char ==

A <code>char</code> in the C programming language is a fixed-size [[byte]] entity, which at one time was large enough to store a character value from [[ASCII]] or other encodings. Since often only 256 different values can be stored in a byte, it is impossible to store characters from [[Unicode]] and other modern sets in a <code>char</code>. Instead larger storage units such as <code>[[wchar_t]]</code>, or more than one byte per character such as [[UTF-8]], are used.

Unfortunately the fact that a character was stored in a byte led to the two terms being used interchangeably in most documentation. This often makes the documentation confusing and/or misleading, and has also led to extremely inefficient implementations of [[UTF-8]] where offsets are replaced with repetitive counting of characters, and has also led to bugs when different systems disagree on the count.

==See also==
* [[Fill character]]
* [[Combining character]]
* [[Universal Character Set characters]]

==References==

<references />

==External links==
{{SpecialChars}}
*[http://www.linfo.org/character.html Characters: A Brief Introduction] by The Linux Information Project (LINFO)
* [http://anubis.dkuug.dk/jtc1/sc2/wg2/docs/tr15285:1998.pdf ISO/IEC TR 15285:1998] summarizes the ISO/IEC's character model, focusing on terminology definitions and differentiating between characters and glyphs

{{data types}}

[[Category:Character encoding]]
[[Category:Data types]]
[[Category:Digital typography]]
[[Category:Primitive types]]

[[cs:Znak (počítače)]]
[[de:Schriftzeichen]]
[[el:Χαρακτήρας (υπολογιστές)]]
[[es:Carácter (informática)]]
[[eo:Karaktro]]
[[fa:نویسه (رایانه)]]
[[fr:Caractère (informatique)]]
[[it:Carattere (informatica)]]
[[he:תו (מחשב)]]
[[hu:Karakter]]
[[ms:Aksara (pengkomputeran)]]
[[mn:Тэмдэгт (компьютерын шинжлэх ухаан)]]
[[my:စာလုံး]]
[[nl:Karakter (informatica)]]
[[ja:キャラクタ (コンピュータ)]]
[[pl:Znakowy typ danych]]
[[pt:Caractere]]
[[ru:Символьный тип]]
[[ckb:نووسە]]
[[zh:字符]]</body> </html>