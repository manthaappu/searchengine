<html> <head> <title>Trusted Computing</title></head><body>'''Trusted Computing (TC)''' is a technology developed and promoted by the [[Trusted Computing Group]].<ref name="mitchell">[http://books.google.com/books?id=9iriBw2AuToC Chris Mitchell, ''Trusted Computing'', Institution of Electrical Engineers, 2005.]</ref> The term is taken from the field of [[trusted system]]s and has a specialized meaning. With Trusted Computing, the computer will consistently behave in expected ways, and those behaviors will be enforced by hardware and software.<ref name="mitchell" /> In practice, Trusted Computing uses cryptography to help enforce a selected behavior. The main functionality of TC is to allow someone else to verify that only authorized code runs on a system. This authorization covers initial booting and kernel and may also cover applications and various scripts. Just by itself TC does not protect against attacks that exploit security vulnerabilities introduced by programming bugs.

TC is controversial because it is technically possible not just to secure the hardware for its owner, but also to ''secure against its owner''. Such controversy has led opponents of trusted computing, such as [[Richard Stallman]], to refer to it instead as '''treacherous computing''', even to the point where some scholarly articles have begun to place [[scare quotes]] around "trusted computing".<ref name="anderson2">[http://www.springerlink.com/content/v8571w5420l26q08/ Ross Anderson, "Cryptography and Competition Policy - Issues with ‘Trusted Computing’ ", in ''Economics of Information Security'', from series ''Advances in Information Security'', Vol. 12, April 11, 2006.]</ref><ref>[http://www.cl.cam.ac.uk/~fms27/papers/2003-stajano-shifting.pdf F. Stajano, "Security for whom? The shifting security assumptions of pervasive computing", ''Lecture notes in computer science'', vol. 2609, pp. 16-27, 2003.]</ref>

The trusted computing platform need not be used to secure the system against the owner. It is possible to leave to the owner rights of authorization and have no centralized authority. It is also possible to build open source stack of trusted modules, leaving for the security chip only the task to guard against unauthorized  modifications. Open source Linux drivers exist <ref>[https://launchpad.net/ubuntu/+source/opencryptoki/2.2.5+dfsg-1ubuntu1.3 Ubuntu opencryptoki package]</ref> to access and use the trusted computing chip. However, uncooperative operating systems can misuse security features to prevent legitimate data exchange.

Trusted Computing proponents such as [[International Data Corporation]],<ref>{{cite web | format = PDF | accessdate = 2007-02-07 | first = Shane | last = Rau | url = https://www.trustedcomputinggroup.org/news/Industry_Data/IDC_448_Web.pdf | title = The Trusted Computing Platform Emerges as Industry's First Comprehensive Approach to IT Security | work = IDC Executive Brief | publisher = International Data Corporation |month=February | year=2006}}</ref> the Enterprise Strategy Group<ref>{{cite web | format = PDF | title = Trusted Enterprise Security: How the Trusted Computing Group (TCG) Will Advance Enterprise Security | work = White Paper | publisher = Enterprise Strategy Group | first = Jon | last = Oltsik |month=January | year=2006 | url = https://www.trustedcomputinggroup.org/news/Industry_Data/ESG_White_Paper.pdf | accessdate = 2007-02-07 }}</ref> and Endpoint Technologies Associates<ref>{{cite web | url = https://www.trustedcomputinggroup.org/news/Industry_Data/Implementing_Trusted_Computing_RK.pdf | title = How to Implement Trusted Computing: A Guide to Tighter Enterprise Security | first = Roger L. | last = Kay |year=2006 | publisher = Endpoint Technologies Associates | accessdate = 2007-02-07 | format = PDF }}</ref> claim the technology will make computers safer, less prone to [[Computer virus|viruses]] and [[malware]], and thus more reliable from an end-user perspective. In addition, they also claim that Trusted Computing will allow [[computers]] and [[Server (computing)|server]]s to offer improved [[computer security]] over that which is currently available. Opponents often claim this technology will be used primarily to enforce [[digital rights management]] policies and not to increase computer security.<ref name="rms">[[Richard Stallman]]. "[http://www.gnu.org/philosophy/can-you-trust.html Can You Trust Your Computer?]".</ref><ref name="Anderson"/>{{Rp|23|date=May 2009}}

Chip manufacturers [[Intel]] and [[AMD]], hardware manufacturers such as [[Dell]], and [[operating system]] providers such as [[Microsoft]] all plan to include Trusted Computing into coming generations of products.<ref>{{cite web | quote = TPMs [Trusted Platform Modules] from various semiconductor vendors are included on enterprise desktop and notebook systems from Dell and other vendors | format = PDF | title = Enhancing IT Security with Trusted Computing Group standards | work = Dell Power Solutions |month=November | year=2006 | url = http://www.dell.com/downloads/global/power/ps4q06-20070160-tcg.pdf | page = 14 | accessdate = 2006-02-07 }}</ref><ref>{{cite web | quote = Windows Vista provides a set of services for applications that use TPM technologies. | url = http://www.microsoft.com/whdc/system/platform/pcdesign/TPM_secure.mspx | title = Trusted Platform Module Services in Windows Vista | date = 2005-04-25 | work = Windows Hardware Development Central | accessdate = 2007-02-07 | publisher = [[Microsoft]] |archiveurl = http://web.archive.org/web/20070515072944/http://www.microsoft.com/whdc/system/platform/pcdesign/TPM_secure.mspx <!-- Bot retrieved archive --> |archivedate = 2007-05-15}}</ref>{{cref|a}}  The [[U.S. Army]] requires that every new small PC it purchases must come with a [[Trusted Platform Module]] (TPM).<ref>{{cite news | url = http://www.securityfocus.com/brief/265 | title = U.S. Army requires trusted computing | publisher = Security Focus | date = 2006-07-28 | first = Robert | last = Lemos | accessdate = 2007-02-07 }}</ref><ref>{{cite web | url = http://www.army.mil/ciog6/news/500Day2006Update.pdf | format = PDF | quote = Strategic goal n. 3 , 'deliver a joint netcentric information that enables warfighter decision superiority' |month=October | year=2006 | title = Army CIO/G-6 500-day plan | publisher = [[U.S. Army]] | accessdate = 2007-02-07 }}</ref> As of July 3, 2007, so does virtually the entire [[United States Department of Defense]].<ref>[http://iase.disa.mil/policy-guidance/dod-dar-tpm-decree07-03-07.pdf encryption of unclassified data]</ref>

==Key concepts==
Trusted Computing encompasses six key technology concepts, of which all are required for a fully Trusted system, that is, a system compliant to the TCG specifications:
# Endorsement key
# Secure input and output
# Memory curtaining / protected execution
# Sealed storage
# Remote attestation
# Trusted Third Party (TTP)

===Endorsement key===
:The endorsement key is a 2048-bit [[RSA]] public and private key pair, which is created randomly on the chip at manufacture time and cannot be changed. The private key never leaves the chip, while the public key is used for attestation and for encryption of sensitive data sent to the chip, as occurs during the TPM_TakeOwnership command.—David Safford<ref>{{cite web | author = [[David Safford|Safford, David]] | url = http://www.linuxjournal.com/article/6633 | title = Take Control of TCPA | date = 2006-10-27 | accessdate = 2007-02-07 | work = Linux Journal }}</ref>

This key is used to allow the executions of secure transactions: every Trusted Platform Module (TPM) is required to be able sign a random number (in order to allow the owner to show that he has a genuine trusted computer), using a particular protocol created by the Trusted Computing Group (the [[direct anonymous attestation]] protocol) in order to ensure its compliance of the TCG standard and to prove its identity; this makes it impossible for a software TPM emulator with an untrusted endorsement key (for example, a self-generated one) to start a secure transaction with a trusted entity. The TPM should be designed to make the extraction of this key by hardware analysis hard, but tamper-resistance is not a strong requirement.

===Memory curtaining===
Memory curtaining extends common [[memory protection]] techniques to provide full isolation of sensitive areas of memory—for example, locations containing cryptographic keys. Even the [[operating system]] does not have full access to curtained memory. The exact implementation details are vendor specific; Intel's Trusted Execution Technology already offers this feature.

===Sealed storage===
Sealed storage protects private information by binding it to platform configuration information including the software and hardware being used. This means the data can be released only to a particular combination of software and hardware. Sealed storage can be used for [[Digital rights management|DRM]] enforcing. For example, users who keep a song on their computer that has not been licensed to be listened will not be able to play it. Currently, a user can locate the song, listen to it, and send it to someone else, play it in the software of their choice, or back it up (and in some cases, use circumvention software to decrypt it). Alternatively, the user may use software to modify the operating system's DRM routines to have it leak the song data once, say, a temporary license was acquired. Using sealed storage, the song is securely encrypted using a key bound to the trusted platform module so that only the unmodified and untampered music player on his or her computer can play it. In this DRM architecture, this will prevent people from buying a new computer, or upgrading parts of their current one except after explicit permission of the vendor of the old computer.

===Remote attestation===<!-- This section is linked from [[Trusted Computing]] -->
Remote attestation allows changes to the user's computer to be detected by authorized parties. For example, software companies can identify unauthorized changes to software, including users tampering with their software to circumvent technological protection measures. It works by having the hardware generate a certificate stating what software is currently running. The computer can then present this certificate to a remote party to show that  unaltered software is currently executing.

Remote attestation is usually combined with public-key encryption so that the information sent can only be read by the programs that presented and requested the attestation, and not by an eavesdropper.

To take the song example again, the user's music player software could send the song to other machines, but only if they could attest that they were running a secure copy of the music player software. Combined with the other technologies, this provides a more secured path for the music: secure I/O prevents the user from recording it as it is transmitted to the audio subsystem, memory curtaining prevents it from being dumped to regular disk files as it is being worked on, sealed storage curtails unauthorized access to it when saved to the hard drive, and remote attestation protects it from unauthorized software even when it is used on other computers. Sending Remote attestation data to a trusted third party , however, has been discouraged in favour of [[Direct anonymous attestation]].

===Trusted third party===
{{cleanup|section|date=May 2010}}

One of the main obstacles that had to be overcome by the developers of the TCG technology was how to maintain anonymity while still providing a “trusted platform”. The main object of obtaining “trusted mode” is that the other party (let's call it Bob), with whom a computer (let's call it Alice) may be communicating, can trust that 'Alice' is running un-tampered hardware and software. This will assure the other party (Bob) that the entity he or she is communicating with (Alice) will not be able to use malicious software to compromise sensitive information on the computer. The consequence of this process is that in order to do this, you have to inform the other party that you are using registered and “safe” software and hardware, thereby potentially uniquely identifying yourself to the other party. This might not be a problem where one wishes to be identified by the other party, e.g., if the user is doing banking transactions over the Internet. But in many other types of communicating activities over the Internet people enjoy the anonymity that the computer provides. The TCG acknowledges this, and allegedly have developed a process of attaining such anonymity but at the same time assuring the other party that he or she is communicating with a “trusted” party.
This was done by developing a “trusted third party”. This entity will work as an intermediary between a user and his own computer and between a user and other users. In this essay the focus will be on the latter process, a process referred to as remote attestation.

When a user requires an AIK (Attestation Identity Key) the user wants its key to be certified by a CA (certification Authority). The user through a TPM (Trusted Platform Module) sends three credentials: a public key credential, a platform credential, and a conformance credential. This set of certificates and cryptographic keys will in short be referred to as "EK".  The EK can be split into two main parts, the private part "EKpr" and the public part "EKpub". The EKpr never leaves the TPM. Disclosure of the EKpub is however necessary (version 1.1). The EKpub will uniquely identify the endorser of the platform, model, what kind of software is currently being used on the platform, details of the TPM, and that the platform (PC) complies with the TCG specifications .
If this information is communicated directly to another party as a process of getting trusted status it would at the same time be impossible to obtain an anonymous identity.  Therefore this information is sent to the privacy certification authority, (trusted third party). When the C.A (Privacy certification Authority) receives the EKpub sent by the TPM, the C.A verifies the information. If the information can be verified it will create a certified secondary key pair AIK, and sends this credential back to the requestor.  This is intended to provide the user with anonymity. When the user has this certified AIK, he or she can use it to communicate with other trusted platforms.
In version 1.2, the TCG have developed a new method of obtaining a certified AIK. This process is called DAA [[Direct anonymous attestation]]. This method does not require the user to disclose his/her EKpub with the TTP. The unique new feature of the DAA is that it has the ability to convince the remote entity that a particular TPM (trusted platform module) is a valid TPM without disclosing the EKpub or any other unique identifier. Before the TPM can send a certification request for an AIK to the remote entity, the TPM has to generate a set of DAA credentials. This can only be done by interacting with an issuer. The DAA credentials are created by the TPM sending a TPM-unique secret that remains within the TPM. The TPM secret is similar but not analogous to the EK.  When the TPM has obtained a set of DAA credentials, it can send these to the Verifier. When the Verifier receives the DAA credentials from the TTP, it will verify them and send a certified AIK back to the user. The user will then be able to communicate with other trusted parties using the certified AIK.  The Verifier may or may not be a trusted third party (TTP). The Verifier can determine if the DAA credentials are valid, but the DAA credentials do not contain any unique information that discloses the TPM platform. An example would be where a user wants trusted status and sends a request to the Issuer. The Issuer could be the manufacturer of the user’s platform, e.g. Compaq. Compaq would check if the TPM it has produced is a valid one, and if so, issues DAA credentials. In the next step, the DAA credentials are sent by the user to the Verifier. As mentioned this might be a standard TTP, but could also be a different entity. If the Verifier accepts the DAA supplied it will produce a certified AIK. The certified AIK will then be used by the user to communicate with other trusted platforms.  In summary the new version introduces a separate entity that will assist in the anonymous attestation process. By introducing the Issuer which supplies a DAA, one will be able to sufficiently protect the user’s anonymity towards the Verifier/TTP.  The issuer most commonly will be the platform manufacturer.  Without such credentials, it will be probably difficult for a private customer or small business or organisation to convince others that they have a genuine trusted platform.

==Known applications==
===Hard drive encryption===
The Microsoft products [[Windows Vista]] and [[Windows 7]] make use of a Trusted Platform Module to facilitate [[BitLocker Drive Encryption]].<ref name="bitlocker">{{cite web | url=http://download.microsoft.com/download/0/2/3/0238acaf-d3bf-4a6d-b3d6-0a0be4bbb36e/BitLockerCipher200608.pdf | title=AES-CBC + Elephant: A Disk Encryption Algorithm for Windows Vista | publisher = Microsoft TechNet |month=August | year=2006 | author = [[Niels Ferguson|Ferguson, Niels]] | accessdate = 2007-02-07 |format=PDF}}</ref>

==Possible applications==
===Digital rights management===
Trusted Computing would allow companies to create a [[Digital rights management]] system which would be very hard to circumvent, though not impossible. An example is downloading a music file. Remote attestation could be used so that the music file could refuse to play except on a specific music player that enforces the record company's rules. This means that only major media players would be able to play your music. Sealed storage could be used to prevent the user from opening the file with another player or another computer. The music would be played in curtained memory, which would prevent the user from making an unrestricted copy of the file while it is playing, and secure I/O would prevent capturing what is being sent to the sound system. Circumventing such a system would require either manipulation of the computer's hardware, capturing the analogue (and possibly degraded) signal using a recording device or a microphone, or breaking the encryption algorithm.

New business models for use of software (services) over Internet may be boosted by the technology. By strengthening the DRM system, one could base a business model on renting programs for a specific time periods or "pay as you go" models. For instance one could download a music file which you only could play a certain amount of times before it became unusable, or the music file could be used only within a certain time period.

===Preventing cheating in online games===
Trusted Computing could be used to combat [[cheating in online games]]. Some players modify their game copy in order to gain unfair advantages in the game; remote attestation, secure I/O and memory curtaining could be used to determine that all players connected to a server were running an unmodified copy of the software.

===Ensuring that people upload in peer-to-peer file sharing networks===
In [[peer-to-peer]] [[file sharing]] networks it is important that the clients upload as well as download, but only the download is usually of interest to the users. Because of this some [[Bittorrent (protocol)|Bittorrent]] servers for example keep track of how much each user uploads and downloads and users with a poor upload/download ratio are banned. For [[Direct Connect (file sharing)|Direct Connect]], client software is available that "cheats" in one way or another, and some people also use third party software to limit their upload speed. With Trusted Computing it would be possible to write peer-to-peer software/protocols that can not be misused like this. For example the client software could refuse to download anything before the upload/download ratio improves, and there would be nothing the user could do to get around that.

===Verification of remote computation for grid computing===
Trusted Computing could be used to guarantee participants in a grid computing system are returning the results of the computations they claim to be instead of forging them. This would allow large scale simulations to be run (say a climate simulation) without expensive redundant computations to guarantee malicious hosts are not undermining the results to achieve the conclusion they want.<ref>{{cite web | url = http://www.hpl.hp.com/personal/Wenbo_Mao/research/tcgridsec.pdf | title = Innovations for Grid Security From Trusted Computing | author = Mao, Wenbo Jin, Hai and Martin, Andrew | date = 2005-06-07 | accessdate = 2007-02-07 |format=PDF |archiveurl = http://web.archive.org/web/20060822043633/http://www.hpl.hp.com/personal/Wenbo_Mao/research/tcgridsec.pdf <!-- Bot retrieved archive --> |archivedate = 2006-08-22}}</ref>

==Criticism==

Trusted Computing opponents such as the [[Electronic Frontier Foundation]] and [[Free Software Foundation]] claim trust in the underlying companies is not deserved and that the technology puts too much power and control into the hands of those who design systems and software. They also believe that it may cause consumers to lose anonymity in their online interactions, as well as mandating technologies Trusted Computing opponents deem unnecessary. They suggest Trusted Computing as a possible enabler for future versions of [[mandatory access control]], [[copy protection]], and [[digital rights management]].

Some security experts<ref>{{cite news | title = Trusted Computing comes under attack | url = http://news.zdnet.co.uk/internet/security/0,39020375,39249368,00.htm | publisher = ZDNet | first = Ingrid | last = Marson | date = 2006-01-27 | accessdate = 2007-02-07 }}</ref><ref name = "Schneier">{{cite news | url = http://www.schneier.com/crypto-gram-0208.html#1 | title = Palladium and the TCPA | date = 2002-08-15 | work = Crypto-Gram Newsletter | author = [[Bruce Schneier|Schneier, Bruce]] | accessdate = 2007-02-07 }}</ref> have spoken out against Trusted Computing, believing it will provide computer manufacturers and software authors with increased control to impose restrictions on what users are able to do with their computers. There are concerns that Trusted Computing would have an [[Anti-competitive practices|anti-competitive]] effect on competition in the IT market.<ref name = "Anderson"/>

There is concern amongst critics that it will not always be possible to examine the hardware components on which Trusted Computing relies, the [[Trusted Platform Module]], which is the ultimate [[hardware]] system where the core 'root' of trust in the platform has to lie.<ref name = "Anderson"/> If not implemented correctly, it presents a security risk to overall platform integrity and protected data. The specifications, as published by the [[Trusted Computing Group]], are open and are available for anyone to review. However, the final implementations by commercial vendors will not necessarily be subjected to the same review process. In addition, the world of cryptography can often move quickly, and that hardware implementations of algorithms might create an inadvertent obsolescence. Trusting networked computers to controlling authorities rather than to individuals may create [[digital imprimatur]]s.

The Cambridge cryptographer [[Ross J. Anderson|Ross Anderson]] has great concerns that "TC can support remote censorship [...] In general, digital objects created using TC systems remain under the control of their creators, rather than under the control of the person who owns the machine on which they happen to be stored (as at present) [...] So someone who writes a paper that a court decides is defamatory can be compelled to censor it &mdash; and the software company that wrote the word processor could be ordered to do the deletion if she refuses. Given such possibilities, we can expect TC to be used to suppress everything from pornography to writings that criticize political leaders."<ref name = "Anderson">{{cite web | url = http://www.cl.cam.ac.uk/~rja14/tcpa-faq.html | title = `Trusted Computing' Frequently Asked Questions: TC / TCG / LaGrande / NGSCB / Longhorn / Palladium / TCPA
Version 1.1 |month=August | year=2003 | author = [[Ross J. Anderson|Anderson, Ross]] | accessdate = 2007-02-07 }}</ref>  He goes on to state that:

:[...] software suppliers can make it much harder for you to switch to their competitors' products. At a simple level, Word could encrypt all your documents using keys that only Microsoft products have access to; this would mean that you could only read them using Microsoft products, not with any competing word processor. [...]

:The [...] most important benefit for Microsoft is that TC will dramatically increase the costs of switching away from Microsoft products (such as Office) to rival products (such as OpenOffice). For example, a law firm that wants to change from Office to OpenOffice right now merely has to install the software, train the staff and convert their existing files. In five years' time, once they have received TC-protected documents from perhaps a thousand different clients, they would have to get permission (in the form of signed digital certificates) from each of these clients in order to migrate their files to a new platform. The law firm won't in practice want to do this, so they will be much more tightly locked in, which will enable Microsoft to hike its prices.<ref name = "Anderson"/>

Anderson summarizes the case by saying "The fundamental issue is that whoever controls the TC infrastructure will acquire a huge amount of power. Having this single point of control is like making everyone use the same bank, or the same accountant, or the same lawyer. There are many ways in which this power could be abused."<ref name = "Anderson"/>

===Digital rights management===
One of the early motivations behind trusted computing was a desire by media and software corporations for stricter [[digital rights management]]  technology to prevent users from freely sharing and using potentially copyrighted or private files without explicit permission.
An example could be downloading a music file from a band: the band's record company could come up with rules for how the band's music can be used. For example, they might want the user to play the file only three times a day without paying additional money. Also, they could use remote attestation to only send their music to a music player that enforces their rules: sealed storage would prevent the user from opening the file with another player that did not enforce the restrictions. Memory curtaining would prevent the user from making an unrestricted copy of the file while it is playing, and secure output would prevent capturing what is sent to the sound system.

===Users unable to modify software===
A user who wanted to switch to a competing program might find that it would be impossible for that new program to read old data, as the information would be "[[vendor lock-in|locked in]]" to the old program. It could also make it impossible for the user to read or modify their data except as specifically permitted by the software.

Remote attestation could cause other problems. Currently web sites can be visited using a number of web browsers, though certain websites may be formatted such that some browsers cannot decipher their code. Some browsers have found a way to get around that problem by [[emulator|emulating]] other browsers. With remote attestation a website could check the internet browser being used and refuse to display on any browser other than the specified one (like [[Internet Explorer]]), so even emulating the browser would not work.

===Users have no control over data===
Sealed storage could prevent users from moving sealed files to the new computer. This limitation might exist either through poor software design or deliberate limitations placed by publishers of works. The migration section of the TPM specification requires that it be impossible to move certain kinds of files except to a computer with the identical make and model of security chip.{{Citation needed|date=June 2009}}

===Users unable to override===
Some opponents of Trusted Computing advocate allowing owner overrides to allow the computer to use the secure I/O path to make sure the owner is physically present, to then bypass restrictions. Such an override would allow remote attestation to a user's specification, e.g., to create certificates that say Internet Explorer is running, even if a different browser is used. Instead of preventing software change, remote attestation would indicate when the software has been changed without owner's permission.

[[Trusted Computing Group]] members have refused to implement owner override.<ref>{{cite news | url = http://www.linuxjournal.com/article/7055 | title = Give TCPA an Owner Override | publisher = Linux Journal | author = [[Seth Schoen|Schoen, Seth]] | date = 2003-12-01 | accessdate = 2007-02-07 }}</ref>  Proponents of trusted computing believe that Owner override defeats the trust in other computers since remote attestation can be forged by the owner. Owner override offers the security and enforcement benefits to a machine owner, but does not allow him to trust other computers, because their owners could waive rules or restrictions on their own computers. Under this scenario, once data is sent to someone else's computer, whether it be a diary, a DRM music file, or a joint project, that other person controls what security, if any, their computer will enforce on their copy of those data. This has the potential to undermine the applications of trusted computing to enforce Digital Rights Management, control cheating in online games and attest to remote computations for [[grid computing]].

===Loss of anonymity===
Because a Trusted Computing equipped computer is able to uniquely attest to its own identity, it will be possible for vendors and others who possess the ability to use the attestation feature to zero in on the identity of the user of TC-enabled software with a high degree of certainty.

Such a capability is contingent on the reasonable chance that the user at some time provides user-identifying information, whether voluntarily or indirectly. One common way that information can be obtained and linked is when a user registers a computer just after purchase. Another common way is when a user provides identifying information to the website of an affiliate of the vendor.

While proponents of TC point out that online purchases and credit transactions could potentially be more secure as a result of the remote attestation capability, this may cause the computer user to lose expectations of anonymity when using the Internet.

Critics point out that this could have a chilling effect on political free speech, the ability of journalists to use anonymous sources, whistle blowing, political blogging and other areas where the public needs protection from retaliation through anonymity.

The TPM specification offers features and suggested implementations that are meant to address the anonymity requirement.   By using a third-party Privacy Certification Authority (PCA), the information that identifies the computer could be held by a trusted third party. Additionally, the use of [[direct anonymous attestation]] (DAA), introduced in TPM v1.2,  allows a client to perform attestation while not revealing any personally identifiable or machine information.

The kind of data that must be supplied to the TTP in order to get the trusted status is at present not entirely clear, but the TCG itself admits that“ Attestation is an important TPM function with significant privacy implications<ref>TPM version 1.2  specifications changes, 16.04.04</ref> ”. It is however clear that both static and dynamic information about the user computer may be supplied (Ekpubkey) to the TTP (v1.1b)<ref>TPM v1.2 specification changes, 2004</ref> , it is not clear what data will be supplied to the “verifier” under v1.2. The static information will uniquely identify the endorser of the platform, model, details of the TPM, and that the platform (PC) complies with the TCG specifications . The dynamic information is described as software running on the computer<ref>TPM v1.2 specification changes,2004</ref>. If a program like Windows is registered in the user’s name this in turn will uniquely identify the user. Another dimension of privacy infringing capabilities might also be introduced with this new technology; how often you use your programs might be possible information provided to the TTP. In an exceptional, however practical situation, where a user purchases a pornographic movie on the Internet, the purchaser nowadays, must accept the fact that he has to provide credit card details to the provider, thereby possibly risking being identified. With the new technology a purchaser might also risk someone finding out that he (or she) has watched this pornographic movie 1000 times. This adds a new dimension to the possible privacy infringement. The extent of data that will be supplied to the TTP/Verifiers is at present not exactly known, only when the technology is implemented and used will we be able to assess the exact nature and volume of the data that is transmitted.

===Practicality===
Any hardware component, including the TC hardware itself, has the potential to fail, or be upgraded and replaced. A user might rightly conclude that the mere possibility of being irrevocably cut-off from access to his or her own information, or to years' worth of expensive work-products, with no opportunity for recovery of that information, is unacceptable.<ref>[http://trousers.sourceforge.net/faq.html#2.3 Trousers FAQ]</ref> The concept of basing ownership or usage restrictions upon the verifiable identity of a particular piece of computing hardware may be perceived by the user as problematic if the equipment in question malfunctions.

===Interoperability===
Trusted Computing requests that all software and hardware vendors will follow the technical specifications released by the [[Trusted Computing Group]] in order to allow interoperability between different trusted software stacks. However, even now there are interoperability problems between the TrouSerS trusted software stack (released as open source software by [[IBM]]) and [[Hewlett-Packard]]'s stack.<ref>{{cite web | work = TrouSerS FAQ | url = http://trousers.sourceforge.net/faq.html#1.7 | title = 1.7 - I've taken ownership of my TPM under another OS... | accessdate = 2007-02-07 }}</ref> Another problem is the fact that the technical specifications are still changing, so it is unclear which is the standard implementation of the trusted stack.
===Shutting out of competing products===
People have voiced concerns that trusted computing could be used to keep or discourage users from running software created by companies outside of a small industry group.  [[Microsoft]] has received a great deal of bad press surrounding their [[NGSCB|Palladium]] software architecture, evoking comments such as "Few pieces of vaporware have evoked a higher level of fear and uncertainty than Microsoft's Palladium", "Palladium is a plot to take over cyberspace", and "Palladium will keep us from running any software not personally approved by Bill Gates".<ref>[http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1203224 E.W. Felten, "Understanding trusted computing: will its benefits outweigh its drawbacks?", ''Security & Privacy, IEEE'', Vol. 1, No. 3, pp. 60-62, ]</ref>  The concerns about trusted computing being used to shut out competition exist within a broader framework of consumers being concerned about using [[bundling]] of products to obscure prices of products and to engage in [[anti-competitive practices]].<ref name="anderson2"/>  Trusted Computing is seen as harmful or problematic to small and [[open source]] software developers.<ref>[http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=1423956 R. Oppliger, R. Rytz, "Does trusted computing remedy computer security problems?", ''Security & Privacy, IEEE'', Vol. 3, No. 2, pp. 16-19, 2005.]</ref>

===Trust===
In the widely used [[public-key cryptography]], creation of keys can be done on the local computer and the creator has complete control over who has access to it, and consequentially their own [[security policy|security policies]].<ref>[http://grouper.ieee.org/groups/1363/ "IEEE P1363: Standard Specifications For Public-Key Cryptography", Retrieved March 9, 2009.]</ref>  In some proposed encryption-decryption chips, a private/public key is permanently embedded into the hardware when it is manufactured,<ref>[http://portal.acm.org/citation.cfm?doid=945464 Tal Garfinkel, Ben Pfaff, Jim Chow, Mendel Rosenblum, Dan Boneh, "Terra: a virtual machine-based platform for trusted computing", ''ACM SIGOPS Operating Systems Review'', Vol. 37, No. 5, pp. 193-206, 2003.]</ref> and hardware manufacturers would have the opportunity to record the key without leaving evidence of doing so. With this key it would be possible to have access to data encrypted with it, and to authenticate as it.<ref>These are the functions of the private key in [http://www.di-mgt.com.au/rsa_alg.html the RSA algorithm]</ref>  It would be fairly trivial for a manufacturer to give a copy of this key to the government or the software manufacturers, as the platform must go through steps so that it works with authenticated software.  {{Citation needed|date=March 2009}}  In order to trust anything that is authenticated by or encrypted by a TPM or a Trusted computer, therefore, one has to trust the company that made that chip, the company that designed the chip, those companies allowed to make software for the chip, and the ability and interest of those companies to not compromise the process.{{Citation needed|date=March 2009}}

It is also critical that one be able to trust that the hardware manufacturers and software developers properly implement trusted computing standards. Incorrect implementation could be hidden from users, and thus could undermine the integrity of the whole system without users being aware of the flaw.<ref name="schoen-promise-risk">[http://pascal.case.unibz.it/handle/2038/871 Seth Schoen, "Trusted Computing: Promise and Risk", ''COSPA Knowledge Base: Comparison, selection, & suitability of OSS'', April 11th, 2006.]</ref>

== Hardware and software support ==
* Since 2004, most major manufacturers have shipped systems that have included [[Trusted Platform Module]]s, with associated [[BIOS]] support.<ref name="tpmvendors">{{cite web | url=http://www.tonymcfadden.net/tpmvendors_arc.html | title = TPM Matrix | author = Tony McFadden | date = March 26, 2006 | accessdate = 2006-05-05 }}</ref> In accordance with the TCG specifications, the user must enable the Trusted Platform Module before it can be used.
* The [[Linux kernel]] has included trusted computing support since version 2.6.13, and there are several projects to implement trusted computing for Linux. In January 2005, members of [[Gentoo Linux]]'s "crypto herd" announced their intention of providing support for TC—in particular support for the Trusted Platform Module.<ref name="lwntc">{{cite web | url=http://lwn.net/Articles/121386/ | title = Trusted Gentoo | date = January 31, 2005 | accessdate=2006-05-05 | work = Gentoo Weekly Newsletter }}</ref> There is also a TCG-compliant software stack for Linux named [http://trousers.sourceforge.net/ TrouSerS], released under an open source license.
* Some limited form of trusted computing can be implemented on current versions of [[Microsoft Windows]] with third party software.
* The Intel [[Classmate PC]] (a competitor to the [[One Laptop Per Child]]) includes a Trusted Platform Module<ref name="classmatepc">{{cite web | url=http://download.intel.com/intel/worldahead/pdf/classmatepc_productbrief.pdf?iid=worldahead+ac_cmpc_pdf | title = Product Brief: Classmate PC | author = Intel | date = December 6, 2006 | accessdate = 2007-01-13 }}</ref>
* [[Intel Core 2|Intel's Core 2 Duo]] processors.{{Citation needed|date=July 2009}}
* [[Athlon 64|AMD's Athlon 64]] processors using the [[Socket AM2|AM2 socket]].{{Citation needed|date=July 2009}}
* [[IBM]]/[[Lenovo]] [[ThinkPad]]s.<ref name="dell_sec_faq_optix">{{cite web|url=http://www1.us.dell.com/content/learnmore/learnmore.aspx?c=us&l=en&s=gen&~id=desktop_security&~line=desktops&~mode=popup&~series=optix&~tab=topic| title=Dell Security Software FAQ|accessdate = 2007-05-24}}</ref>
* [[Dell OptiPlex|Dell OptiPlex GX620]].<ref name="dell_sec_faq_optix" />

==See also==
*[[Trusted Platform Module]]
*[[Trusted Network Connect]]
*[[Next-Generation Secure Computing Base]] (formerly known as Palladium)
*[[:wikt:Transwiki:Glossary of legal terms in technology|Glossary of legal terms in technology]]

==References==
{{Reflist|2}}

==External links==
{{External links|date=June 2010}}
===Official sites===
*[http://www.trustedcomputinggroup.org/home Trusted Computing Group] (TCG)—Trusted Computing standards body, previously known as the TCPA
*[http://www.trustedcomputinggroup.org/solutions TCG solutions page]  information on TCG Members' TCG-related products and services

===Software applications===
*[http://www.opentc.net/ openTC] ─ Public research and development project (esp. trusted operating systems) funded by the European Union to create open source trusted and secure computing systems.
*[http://www.emscb.de/ EMSCB] ─ European Multilaterally Secure Computing Base, Public research and development project for trusted computing applications on open source software.
*[http://forum.emscb.org/ Forum for Open SW based on TC] ─ TPM drivers and support forum for LINUX etc.
*[http://enforcer.sourceforge.net/ Enforcer] ─ Linux module that use Trusted Computing to ensure no tampering of the file system.
*[http://www.microsoft.com/resources/ngscb/default.mspx Next-Generation Secure Computing Base (NGSCB)]—Microsoft's trusted computing architecture (codename Palladium)
*[http://trousers.sourceforge.net/ TrouSerS ─ The open-source TCG Software Stack] with [http://trousers.sourceforge.net/faq.html FAQ] explaining possible problems using a TPM
*[http://trustedjava.sourceforge.net/ Trusted Java] ─ API Java for TrouSerS
*[http://tpm-emulator.berlios.de/ TPM Emulator] ─ Software-based TPM emulator

===Criticism===
*[http://www.lafkon.net/tc/ Trusted Computing: An Animated Short Story] ─ by Benjamin Stephan and Lutz Vogel
*[http://www.gnu.org/philosophy/can-you-trust.html Can You Trust Your Computer?] ─ by [[Richard Stallman]]
*[http://www.schneier.com/blog/archives/2006/05/who_owns_your_c.html Who Owns Your Computer?] ─ by [[Bruce Schneier]]
*[http://drm.info/ DRM.info] ─ What you should know about Digital Restrictions Management (and “Technological Protection Measures” (TPM))
{{FOSS}}

[[Category:Cryptography]]
[[Category:Business law]]
[[Category:Copyright law]]
[[Category:Trusted computing| ]]
[[Category:Microsoft Windows security technology]]

[[cs:Trusted Computing]]
[[de:Trusted Computing]]
[[et:Trusted Computing]]
[[es:Trusted Computing]]
[[fr:Informatique de confiance]]
[[it:Trusted computing]]
[[nl:Trusted computing]]
[[pl:Trusted Computing]]
[[sl:Trusted computing]]
[[sv:Trusted Computing]]
[[vec:Trusted computing]]
[[zh:可信计算]]</body> </html>